Redis
	- REmote DIctionary Server
	- data store that is also used as message queue
	- NoSQl in-memory key-value data store
	- data types supported
		- strings, hashes, lists, sets,...
	- data storage
		- by default, in-memory; for fast read/write operations.
		- Redis Database for data persistence
			- point-in-time snapshots of a dataset at specified intervals
	- USAGE:
		- cache to store frequently access data
			- queried database results
			- API responses
			- session data in web applications, messaging/streamsing systems


	1) Redis
		- I worked with redis in multiple projects, mainly as a cache.
		- Also, worked along with celery, as a mesage broker

	2) fastapi
		- I worked with fastapi for creating both web app and REST APIs.
		- I worked with Redis-fastapi for
			- Rate limiting with Redis Counter, which is natively supported
			- Cache frequent database queries & Cache Serialization rendering
			= Also, used redis for storing session data
			- Also, used Redis pub/sub channels to send messages between FastAPI processes/servers
			- And, used Redis lists as queues to coordinate background jobs and workers

Celery
	In my web applications, for the long running jobs, I need to go for distributed setup, to avoid timeouts, for frontend.
	So, I  used celery to register those jobs, and sent back the celery job id to frontend. It will use polling mechanism to check for completion of the job.

	On other side, this celery is interfaced with Redis (in one project) or RabbitMQ (in another) for processing.

	Celery was also used for scheduling periodic jobs, In the celery interface/flower

- Queues
=========
- ADVANTAGES
	1) To decouple applications
	2) To handle asynchronous processing
	3) To provide fault tolerance
	4) To improve performance

Apache Kafka
	- message queues with database-like durability guarantees

Elasticsearch/Solr
	- full text search server

Memcached
	- for in-memory cache


Reliability
	The system should continue to work correctly (performing the correct function at the desired level of performance) even in the face of adversity (hardware or software faults, and even human error). See “Reliability”.

Scalability
	As the system grows (in data volume, traffic volume, or complexity), there should be reasonable ways of dealing with that growth. See “Scalability”.

Maintainability
	Over time, many different people will work on the system (engineering and operations, both maintaining current behavior and adapting the system to new use cases), and they should all be able to work on it productively. See “Maintainability”.


failure vs fault
	A fault is usually defined as one component of the system deviating from its spec, whereas a failure is when the system as a whole stops providing the required service to the user.
It is impossible to reduce the probability of a fault to zero; therefore it is usually best to design fault-tolerance mechanisms that prevent faults from causing failures.


Netflix Chaos Monkey
	TO check the fault-tolerance,
		t can make sense to increase the rate of faults by triggering them deliberately—for example, by randomly killing individual processes without warning

Scalability is the term we use to describe a system’s ability to cope with increased load.

 response time is what the client sees: besides the actual time to process the request (the service time), it includes network delays and queueing delays. Latency is the duration that a request is waiting to be handled—during which it is latent, awaiting service [


- Service Oriented Architecture (SOA)
--------------------------------------
	- It is an approach to software design and development that focuses on creating modular and reusable components, or services, that can be shared and combined to create more complex applications.
	- All services will be loosely coupled, so
		- can be developed and maintained independently
		- and it enables interoperability between different platforms and programming languages.
	- SOA is often used in large-scale enterprise applications to break down systems into smaller, modular services.
	- SOA is supported by a variety of technologies and standards, such as web services, RESTful APIs, and XML and JSON data formats.

	- ADVANTAGES
		- Interoperability, Loose coupling, Abstraction, Granularity
	- LIMITAIONS
		- Increasing interdependencies
		- Single point of failure
		- Limited scalability

	- Microservices can address these limitations.
	- Microservices are a type of service-oriented architecture that emphasizes small, independent services that work together to form a larger application.


monolithic vs microservice
==========================
In Monolithic,
	All components are part of a single unit
	Everything is developed, deployed and scaled as 1 unit
	App must be written with 1 tech stack
	Teams need to be careful to not affect each other's work
	1 single artifact, so we must redeploy the entire application on each update

	Challenges
		- Application is too large and complex
		- Parts are more tangled into each other
		- You can only scale the entire app, instead of a specific service.
		- Difficult if services need different dependency versions
		- Release process takes longer
		- On every change, the entire application needs to be tested
		- Entire applcation needs to be built and deployed
		- Bug in any module can potentially bring down the entire application

In Microservices,
	Split application into smaller, independent services based on business functionalities
	Apps should be Loosely coupled
		Separation of concerns: means 1 service for 1 specific job
		Self-contained & independent
		Each microservice has its own version

	Communication should be via API calls
		Each service has its own API
		They can talk to each other, by sending requests to the respective API endpoints

		Communication can be THREE ways
		1) In Synchronous communication,
			means each service waits for the response from another service.

		2) In asynchronous communication,
			communication is via messages using a message broker like RabbitMQ, etc
			common distribution patterns:
				Publish/Subscribe (PubSub)
				Point-to-Point messaging
		3) In Communication in Kubernetes using service Mesh,
			There will be a helper service which will take care of complete communication logic. So, we need not code this logic into microservices

		Challenges
			- Configure the communication between services
			- More difficult to monitor with multiple instances of each service
			  distributed across servers

			In Kubernetes, serviceMesh, we can address both these challenges.

	ref - https://microservices.io/patterns/microservices.html

serviceMesh
	adds uniform networking capabilities across the stack in a way that is decoupled from application code
	Service meshes extend a cluster manager like Kubernetes to offer
		- observability metrics,
		- service discovery,
		- load balancing,
		- IT operations monitoring, and
		- failure recovery for microservices and containers.
	In market, to the best of my knowledge, for serviceMesh, there were tools like
		- Istio
		- Linkerd
		- Consul Connect
		- Kuma
		- Maesh
		- ServiceComb-mesher
		- Network Service Mesh (NSM)
		- AWS App Mesh
		- OpenShift Service Mesh by Red Hat

	AWS App Mesh is the tool, I used for serviceMesh
		AWS App Mesh makes it easy to run services by providing consistent visibility and network traffic controls, and helping you deliver secure services. App Mesh removes the need to update application code to change how monitoring data is collected or traffic is routed between services. App Mesh configures each service to export monitoring data and implements consistent communications control logic across your application.


Redis Usecases
---------------
	Slow latest items listings in your home page
	Leaderboards and related problems
	Order by user votes and time
	Implement expires on items
	Counting stuff
	Unique N items in a given amount of time
	Real time analysis of what is happening, for stats, anti spam, or whatever
	Pub/Sub
	Queues
	Caching

- Airflow
-------
	DAG means Directed Acyclic Graph.
	is a collection of all the tasks you want to run, organized in a way that reflects their relationships and dependencies.
	A DAG is defined in a Python script, which represents the DAGs structure (tasks and their dependencies) as code.

- Apache Kafka
-------------
	- Kafka is a distributed streaming platform for building real-time data pipelines and streaming applications.
	- USAGE/ Usecases
		- Stream processing, website activity tracking, metrics collection, log aggregation, event sourcing, commitment log for distributed systems.
	- Advantages
		- High Availability
			- Kafka replicates data across brokers using a replication factor. If a broker fails, replicas on other brokers ensure data is preserved.
		- Message persistence
			- Messages are persisted to disk in the broker using a configurable retention period.
			- This allows replay of messages if needed.
		- scalability
			- Kafka scales via partitioning of topics across brokers. More partitions allow greater parallelism.

	- Kafka Components:
		1) Topic 		- A particular stream of data, similar to a table in a database. Messages are stored in topics.
		2) Producer 	- Creates new messages and publishes them to Kafka topics.
		3) Consumer 	- Subscribes to topics and processes messages published to them.
		4) Broker 		- Kafka cluster is composed of multiple brokers which manage data persistence and replication.
		5) Zookeeper	- Kafka uses Zookeeper for coordination between brokers and consumers, for configuration, cluster management.
		6) Kafka Connect- Integration framework to build producers and consumers that import/export data from Kafka.

	- Kafka Partitioning
		- Kafka's partitioning allows large data streams to be divided into parallel pipelines for scalability.
		- The criteria depends on data access patterns.
		- Partitioning criteria:
			1) Hash Partitioning
				- A hash of the key is used to determine partition.
				- Ensures messages with the same key go to the same partition.
			2) Range Partitioning
				- Messages are partitioned by key ranges for sorting and grouping.
			3) Round Robin 	- Messages are assigned to partitions in a round robin fashion to balance load.
			4) Time Based 	- Messages are partitioned by timestamp to group events together.
			5) Random 		- Messages are randomly distributed across partitions.


message queue vs kafka
----------------------
	- We can consider queue systems like Messag queue for:
		- Exactly once delivery, and to participate into two phase commit transaction
		- Recall messages in queue are kept until consumer(s) got them.
		- Asynchronous request / reply communication: the semantic of the communication is for one component to ask a second command to do something on its data.
			This is a command pattern with delay on the response.

	- We can Consider streaming system, like Kafka, as pub/sub and persistence system for:
		- Publish events as immutable facts of what happened in an application
		- Get continuous visibility of the data Streams
		- Keep data once consumed, for future consumers, for replay-ability
		- Scale horizontally the message consumption

- Message brokers
------------------
	- They have publishers, message brokers and consumers
	- A message broker delivers information like messages (or events) from a producer to a consumer.
	- When consumers safely process the message, they send an acknowledgment back to the broker.
	- The broker will then safely remove the message.
	- Message brokers typically allow for intelligent routing.
	- The logic to route messages based on rules can be configured within the broker itself.

- Event-streaming brokers
-------------------------
	- An event-streaming broker also supports the delivery of events from publisher applications to consumers.
	- The main difference is that streaming brokers do not remove acknowledged messages.
	- Streaming brokers allow you to replay events as needed.
	- Event-streaming brokers support high-volume throughput, but in order to do this, they often do not support intelligent routing within the broker.
	- Intelligent message routing is normally delegated to client-side applications.

- Messaging
---------
	- Messages transport a payload and messages are persisted until consumed.
	- Message consumers are typically directly targeted and related to the producer who cares that the message has been delivered and processed.

- Events
---------
	- Events are persisted as a replayable stream history.
	- Event consumers are not tied to the producer.
	- An event is a record of something that has happened and so can't be changed. (Like a history, immutable and cant be changed)

- Event Driven Architecture (EDA)
-------------------------
	- It is a software design that reacts to changes of state (events) and transmits these events using a decoupled architecture.
	? Decoupled Architecture Patterns
		- Publish-Subscribe (Pub-Sub) Pattern
			- Here, producer publishes the event and subscriber watches for events, but neither are dependent on the other.

- Event Sourcing vs Event Streaming
----------------------------------
	- While event streams promote more accessible communication between systems,
	  event sourcing provides event history by storing new events in an append-only log.


- Ansible
----------
- Its a devops tool for orchestration, automation, configuration, and management of IT infrastructure
- LIMITATIONS include
	- No debugging, performance, complex data structures and control flow. Complex data structures. Many network automation tasks require complex data structures. One of the first things I considered when learning Ansible was to use it to perform network discovery.

- Ansible Playbook
	- It is a like a blueprint of automation tasks.
	- These tasks can range from installations, to configurations.
	- Ansible playbooks are executed on a set, group, or classification of hosts, which together make up an Ansible inventory.

- Ansible Tower
	- It is a web-based UI that provides a dashboard with status summaries of all the hosts,
		allows quick deployments, and
		monitors all configurations.
	- Also, the tower allows us to share the SSH credentials without exposing them,
	- logs all the jobs, manage inventories graphically and syncs them with a wide variety of cloud providers.
	- It also has REST API, for integrations; I used in one of the projects


- Ansible Vault
	- It is used to keep sensitive data such as passwords instead of placing it as plaintext in playbooks or roles.
	- Any structured data file or any single value inside the YAML file can be encrypted by Ansible.
	- To encrypt a file,
		ansible-vault encrypt foo.yml bar.yml baz.yml
	- And similarly to decrypt,
		ansible-vault decrypt foo.yml bar.yml baz.yml

- Ansible Facts
	- Ansible facts are data related to the remote systems, including
		- operating systems,
		- IP addresses,
		- any attached filesystems, and more.
	- We can access this data in the ansible_facts variable.
	- By default, we can also access some Ansible facts as top-level variables with the ansible_ prefix.

	- Also, We can define three types of custom facts in Ansible.
		1) Global facts: These facts are accessible from every host in your inventory file.
		2) Group facts: These facts are only accessible from a specific set of hosts or a host group.
		3) Host facts: These facts are only accessible from a particular host.

- Ansible callback plugin
	- callback plugins help in adding additional behavior to ansible when responding to events.
	- By default, callback plugins control most of the output that we see, when running command line programs,
	  Also, we can use callback plugins to add additional output, integrate with other tools and marshal the events to a storage backend.
	- Examples
		- The log_plays callback is an example of how to record playbook events to a log file, and the mail callback sends email on playbook failures.
		- The say callback responds with computer synthesized speech in relation to playbook events.

Enabling callback plugins

ref - https://www.middlewareinventory.com/blog/ansible-playbook-example/
