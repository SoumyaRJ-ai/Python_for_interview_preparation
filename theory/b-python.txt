Python Modules
	Requests     : for consuming APIs
	Re           : for regular expressions
	Scikit-learn : for machine learning - I used for creating linear regression model
	BeautifulSoap: for parsing html content. Used when I worked on web crawling/Scraping
	NumPy        : Advanced linear algebra and NumPy array operations
	Matplotlib   : Visualisation and data plotting in 2 or 3 dimensions.
	IPython      : Increasing console interactivity.
	Jupyter notebook: for interactively exploring the datasets and other functions
	Pandas       : Data manipulation and analysis, mainly through dataframes and tables.
	boto3        : For connecting and managing AWS Cloud resources
	paramiko	 : for connecting to linux machines
	fabric		 : for connecting to windows machines

	file system modules like
		csv files with csv and pandas modules
		json files with json and pandas modules
		yaml files with pyyaml module
		Excel files with openpyxl, Xlsxwriter, xlrd and pandas modules
		pdf files  with reportlab, pypdf2 modules
		image files with Pillow and tesserect modules

Frameworks
	Django, flask, fastapi

Files I worked with
--------------------
	- pdf files using modules like reportlab, pypdf2
	- image files using tesserect, Pillow
	- CSV, .dat files, tsv files with pandas

Python Questions
-----------------
- Basic Data Types - Int, Float, Str, None, bool
- Built-in Data Structures - List, Tuple, set, Dictionary

- List
	- Mutable object - it is editable. we can add , remove any element in it.
	- indexed and retains the order of initialization
	- will retain duplicates and can store any data type

- Tuple
	- same as a list, but once created, we can't change any element in it .
	- it is immutable object

- Set
	- mutable object - we can edit it
	- unordered and wont store duplicates
	- will store only immutable objects(int, float, string, frozenset, tuple)
	- frozenset is same like set, but is immutable

- Dictionaries
	- They store in key: value relation
	- keys should be immutable and unique, and hashable
	- Values can be mutable
	- They are called as HashMap in other languages
	- ex: {1:2, 3:4, 5:6}

- conclusions
	- List is suitable when the order of storage is needed and/or
	  if there were more writes.
	- Dict suitable when there were more reads
	- Set is suitable when unique values are needed and/or set operations like union,
	  intersection, etc are needed.
	- Tuple is suitable when there need to be immutability

- hashable
	- An object is hashable if it has a hash value which never changes during its lifetime

- List vs Tuple
	- List is mutable object, means we can edit the object like append, delete, ..
	- Tuple are faster than list
		- Tuples are stored in a single block of memory. Tuples are immutable so,
		It doesn't require extra space to store new objects.
		- Lists are allocated in two blocks:
			1. fixed one with all the Python object information, and
			2. variable sized block for the data.
	- Tuples is that they use less memory where lists use more memory
	- USAGE:
		List is used when we need to make changes in code, say adding values while loop .
		Tuple is used when we wont change something in the code

- append vs extend
	- both adding elements in last of list
	- with append, we can add either single element or an iterable
	- it will add at the end as it is
	- whereas extend works with iterable objects only, but adds in same dimension

- List vs Dict
	- list is suitable when the order of element is preferred.
	- dict is suitable when there were more reads. dict has O(1) for search an element, as
	  it stored each element uniquely with its hash.
	- Insertion time is less in list

- List vs Array
	- list is builtin data structure in python
	- we can either have all elements of same type, or different type

	- array is available from numpy
	- IN array, we need to have all elements of same type.
	- whenever i have to store all elements of same type, as arrays are more performant than lists.

- range vs xrange
	- xrange of python2 , is renamed as range in python 3
	- range in python2 results a list, whereas in python 3, range results in range object.
	- range takes three arguments - start number, stopNumber and step ;
	  then, will return the sequence for those values

- Pickling
	- Pickling means Python object to flat file conversion
	- unpickling means flat file to python object conversion
	- This process is also called serialization/deserialization
	- Other serialization formats are json, yaml, ...
	- we use it when we need to pass python object to other language processes, and vice versa.

	json.dumps for converting python string to JSON string
	json.dump  for converting python string to JSON file

	json.loads for loading JSON string to python string
	json.load  for loading JSON string to python file

Shallow vs Deep copy
- It is used in mutable objects like lists and dictionaries.
- Shallow copy is used for single dimension mutable objects
- Deep copy is used for multiple dimension mutable objects

- lambda function
	- one liner function, mainly useful for evaluating a single expression that is
	  supposed to be evaluated only once.
	- SYNTAX is lambda arguments: expression
	- We need not define a complete function. We can use it instantly for the purpose.
	- It can be passed as a parameter to a higher-order function, like filter(),
	  map(), and reduce().
	- example
		- if we have to increment all values in a list by one,
				map(lambda x:x + 1, range(10))
	- And, coming to the con side,
		- It can’t perform multiple expressions.
		- It can easily become cumbersome, for example when it includes an if-elif-…-else cycle.
		- It can’t contain any variable assignments (e.g., lambda x: x=0 will throw a SyntaxError).
		- We can’t provide a docstring to a lambda function.

- enumerate
	- Its a build-in function, mainly used when iterating over any iterable,
	  to get the loop index.
	- Ex:
			for loop_index, num in enumerate([1, 2, 3, 4]:
				print(loop_index, num

List comprehension
	- rewriting the for loop in single line.
	- As it creates a code object, it will be slighty faster.
	- But, comprehensions will reduce the readability of code.
	- Based on the braces we store with, comprehensions include
		- list comprehension
		- set comprehension
		- dictionary comprehension
		- Tuple comprehension is called generator expression

*args **kwargs
	- They are used for creating variadic functions.
	- *args will enable a function to take zero or any number of arguments.
	  It will store all the values in a tuple

	- **kwargs will enable the function to take any number of keyword arguments.
	  It will store all values in a dictionary.
	  Ex: func(a=1, b=2, c=3)  will create a dict {'a': 1, 'b': 2, 'c': 3}


constructor
	- its the method, which will be called, automatically, when we
	  instantiate the class instance
	  __init__() is the method for the same

destructor
	- its the method, which will be called, automatically, when we
	  delete an instance, or at the end of scope of the instance.
	  __del__() is the method for the same


overloading vs overwriting
	- If we define two functions/methods with same name, but different no. of arguments,
	  then, if we can call both functions/methods individually, it is called Overloading.

	- Python does not support overloading, but only overwriting is supported
	- Overwriting means among the defined two functions, as both have same name,
	  the latest defined function/method will overwrite others.


- range() vs xrange()
	- In python 2,
		- range will give list of integers
		- xrange will give a xrange object, which will give values only when iterated.
	- In python3, xrange is renamed as range.

- copy vs deepcopy
	- This problem occurs in mutable objects i.e., list, dictionary
	- when working with mutables, when we assign a
			list1 = list2
		it will not create new object
		it
		both wil refer to the same object
		so, if you change in one list, it will reflect in others
		to avoid, we go with copy
		using
		copy -- module

- try-exception blocks
	1) Try   --- executed every time
	2) Except--- executed when there is exception in try block,
				 check if it can handle break code if it cant

	3) Else  --- executed when no exception in try block
	4) Finally-- executed every time  — irrespective of failure  –
				 it is like for file closing, etc ….

Debugging in python
- Either using pdb or ipdb modules, or using breakpoint() function

- OOP
	- Object Oriented Programming
		- I use Object-Oriented Programming and Design predominantly.
		- It gives us the scalability in code to adapt any requirement changes.

 	- There are 4 principles:
		1) ENCAPSULATION - with public, protected and private variables/methods
				public variable -- it a variable is starting with no underscore
				protected variable -- if it is starting with SINGLE underscore
				private variable -- if it is starting  with TWO underscores

			We can access all variables  of all classes irrespective of public or private or protected.
			This name mangling is to avoid accidental override

		2) ABSTRACTION:
			- It is a process of hiding implementation details and showing only functionality to the user.

		3) INHERITANCE:
			- python supports single, multiple and multi-level inheritance, using MRO (Method Resolution Order)
					single ---> one parent & one child
					multiple --> two parents & one child
					multi-level -->  parent1 => child ==> subChild
			- Method Resolution Order is the order in which base classes are searched for a member during lookup.
			  hybrid & hierarchical

		4) POLYMORPHISM: It is an ability of object to behave in multiple form.
			- For better code resusability, common code we write in one class,
				and inherint in other classes

			Ex: + operator, It will work differently in different contexts
					addition operation between integers
					List concatenation operator between lists
					Tuple concatenation operator between tuples

self
	- Its the placeholder for the instance being passed to the class


class variables vs instance variables
	- Class variable is used to work with class methods
	- Instance variables are just associated with instance methods

	- Say, we have created  5 instances  from a car class
	  We need to give unique id to all the car instances,
	  Then, We can track using the class variables
	- Instance variables of each instance, will be isolated
	  from that of other instances.

Abstract Classes
	- These are called as blueprint for other classes
	- These classes are used for inheritance only, and not for creating instances.

- Difference between python2 and python3
	- Default encoding is ASCII in python2, whereas it  is UTF-8 in python3
	- There were both old & new style classes in python2, whereas in python3, we have only new style classes.
	- IN python2, range, map, filter will return list; where these are iterators in python3.

- python 2 to 3
	- I used python built-in module, lib2to3 , for migrating from python2 to python3.
	- Wrote code with six module to write compatible code, for both python2 and 3, during migrating phase.
	- Challenges during conversion
		- In python2, we can compare string and int; We cant do the same with python3
			- I wrote wrapper to handle it
		- DEPENDENCY MANAGEMENT is another difficult thing, as some modules are either not available in python3,
			or the latest features are not available in python3 modules.

- Virtual environment
	- It is like a container, for isolating the project dependencies
	- When in same server, we need to execute different versions, Or same python version, with different module
		versions, we go with a virtual environment.
	- virtual environments can be created using modules like
		- virtualenv
		- pipenv, or
		- poerty

	- Using virtualenv module,
		command to create virtual enviromment is
			virtualenv venv

		To activate the virtual enviromment,
			venv/scripts/active - in windows
			venv/bin/active - in linux/mac

- .py vs .pyc files
	❏ .py files contain the source code of a program. Whereas, .pyc file contains the bytecode of your
	program.
	❏ Python compiles the .py files and saves it as .pyc files, so it can reference them in subsequent
	invocations.
	❏ The .pyc contain the compiled bytecode of Python source files. This code is then executed by
	Python's virtual machine.

- Generators
	- are the functions with yield, instead of return
	- They are useful for large computations, like reading a large file, or creating 1000 prime numbers, or so.
	- Generators follow the "STATE SUSPENSION"
		- we can get one value at a time using next() builtin function,
			or iterate , or convert to list, tuple or set, to get all values
	- return vs yield
		- return is the last statement to execute in any function
		- yield is a keyword in python
			- If yield is placed within function definition, it becomes generator

		- PEP8 - don't use both return & yield in same function

		def grepper_gen():
			yield "add"
			yield "grepper"
			yield "answer"
		grepper = grepper_gen()

- Iterator
	- Any python iterable object can be converted to an intertor using iter() protocol
	- iterator can be created from any iterable object

- Decorators
	- Generally, when some code is repeating, we will create a function, reuse the code.
	- If there were more than one function, with some part of the code which is common among all,
      in that case, we extract common code, create a closure for it, and use it as a decorator.
	- built-in decorators are classmethod, staticmethod and property
	- I created custom decorators for calculating the time taken by functions, or
	  like logging the events, etc

- Map
	- Higher-order function, which is designed to work on other functions
	- map will superimpose a function on one or more iterables
	- say, we want to get double of all values in a list
		map(lambda x:x * 2, range(9))

	- In python2, map will result a list, where as in python3, it will return an iterator
	  object.
	- Other higher order functions are Filter, Zip and Reduce

- Filter
	- This higher-order function will superimpose a function, on one or more iterables
	  and return the values, for whom the function returns boolean true.

- Zip
	- It will create pairs, on two or more iterables.
	- It will create pairs to the minimum size, among the iterables;
	  and discard asymmetric size values.

- Reduce
	- It will iterate on a single iterable with the given function
	- It will take a function and work with every two consecutive elements in that iterable
	- Finally, returns a single value as result.
	-  Ex: for calculating factorial of a number, etc.
	- Its a build-in function in python2, whereas in python 3, it is part of functools module

- pass, continue and break
	- pass is like a TODO. It does nothing, except to hold the syntax
	- say we need to have a class, or a condition, but want to write logic in future,
	  we use "pass" to retain the syntax.

	- continue will skip the current loop, whereas
	  break will stop the entire loop


- GIL Problem
	- GIL means Global Interpreter Lock
	- Simply, it means "One thread runs Python, while others sleep or await I/O."

	- In Cpython, as it goes with reference based assignment, if two threads are trying to update,
	  say, the same list, it can lead to data races, and deadlock.
	- To avoid deadlocks, it will lock a single thread, safely execute it, and release it.
	- Due to this, we can't achieve concurrency with python, unlike other languages.

	- Next solution is multiprocessing. But, it is resource exhaustive. And, the maximum limit
	 on the processes which can be created, is limited to the system hardware limits.
	- So, from python 3.6, with the advent of async and await keywords, I am using the asyncio
	 based non-blocking execution.
	- Here, within the single thread event loop, we will invoke all child threads; which is a solution
	  to this GIL problem

- Multiprocessing vs Multithreading
	- Tasks are of two types
	- Multithreading for IO-bound tasks.
	- Multiprocessing for CPU-bound tasks.
		- computationally-intensive tasks such as compression or hashing.

- Threading vs Asyncio
	Threading
		- In threading, OS actually knows about each thread and can interrupt it at
			any time to start running a different thread.
		- It is Preemptive Multitasking
		- code in the thread doesn't need to do anything to make the switch.
		- difficult as OS can pause/resume thread "AT ANY TIME"
	Asyncio
		- Cooperative Multitasking
		- Tasks must cooperate by announcing when they are ready to be switched out.
		- You always know where your task will be swapped out.
		- Suitable for event-driven architectures

process vs thread
	- processes do not share memory and run on a single core.
	  They are better for compute-intensive tasks that do not have to communicate
	  with each other.
	- threads share memory.
	  In Python, due to the Global Interpreter Lock (GIL), two threads cannot operate
	  at the same time in the same program.
	  As a result, only some operations can be run in parallel using threads.

- thread vs process
	-------------------------------------------------------------------------------------------
		PROCESS								    |			THREAD
	-------------------------------------------------------------------------------------------
	- Processes are heavyweight operations.	    | Threads are lighter weight operations.
	- Each process has its own memory space.    | Threads use the memory of the process they belong to.
	- Inter-process communication is slow as    | Inter-thread communication can be faster than inter-process communication
	  processes have different memory addresses.| because threads of the same process share memory with the process they belong to.
	- Context switching between processes is    | Context switching between threads of the same process is less expensive
	  more expensive.
	- Processes don’t share memory with other   | Threads share memory with other threads of the same process.
	  processes.

concurrency vs parallelism
 - “Concurrency is about dealing with lots of things at once.
    Parallelism is about doing lots of things at once”

- cooperative multitasking
	- Whenever a thread begins sleeping or awaiting network I/O, there is a chance for
	  another thread to take the GIL and execute Python code.

- preemptive multitasking
	- CPython has it. Something similar to time slicing
	- If a thread runs uninterrupted for 1000 bytecode instructions in Python 2, or runs
	  15 milliseconds(set via sys.setswitchinterval()) in Python 3, then it gives up
	  the GIL and another thread may run.

- Thread Safety
	- If a thead loses GIL at any moment, we should ensure that code is thread safe.
	- Many Python operations like sort(), ... are atomic.
	- GIL wont switch in middle of automatic operations.
	- EX: A thread cannot be interrupted in the middle of sorting, and other threads never
	      see a partly sorted list, nor see stale data from before the list was sorted.

	- Locks are needed to protect shared mutable state

Atomic Operations
	- All  single bytecode instruction. We can checking using dis module; dis.dis(object)
	- Assuming L, L1, L2 are lists, D, D1, D2 are dicts, x, y are objects, i, j are ints,

	L.append(x)
	L1.extend(L2)
	x = L[i]
	x = L.pop()
	L1[i:j] = L2
	L.sort()
	x = y
	x.field = y
	D[x] = y
	D1.update(D2)
	D.keys()

PYTHONPATH
- It is an environment variable that you set before running the Python interpreter.
- PYTHONPATH, if it exists, should contain directories that should be searched for modules when using import.
- If PYTHONPATH is set, Python will include the directories in sys.

Non-Automic Operations
	i = i+1
	L.append(L[-1])
	L[i] = L[j]
	D[x] = D[x] + 1

- context managers
	- will allow you to allocate and release resources precisely when you want to.
	- Examples include when working with
		- file operations, database or socket connections, etc.
	- They implement the "finally" block once we come out of the context manager indentation.

	- we can do with the 'with' keyword, like

		with open('file_name.txt', 'r') as fh:
			data = fh.read()

	- we need not close the file handler. Once it comes out of the context indentation,
	  it will automatically close
I	- we can create custom context managers, using the dunder methods,
      __enter__() and __exit__().
	- I remember using it to track the file operations.

		class File:
		  def __init__(self, filename, method):
			self.file = open(filename, method)

		  def __enter__(self):
			print("Enter")
			return self.file

		  def __exit__(self, type, value, traceback):
			print(f"{type}, {value}, {traceback}")
			print("Exit")
			self.file.close()

		with File("file.txt", "w") as f:
		  print("Middle")
		  f.write("hello")
		  raise Exception()
		  raise FileExistsEoor()

- call by value vs call by reference
	- python supports both call by value and call by reference.
		- For immutables, it is call by values
			- by default, means changes within the function were not reflected outside
			- in variables are defined as global, local changes cAN be reflected outside
			  - that is in that case, it is call by reference
		- For immutables , if you define as global,  – it is be call by reference

unittesting
	- I used modules like unit test and pytest.
	- Generally, we follow TDD - test driven development
	- It means that first write the unit tests and then write logic to address them.
	- This way, we can assure that code is more reliable, handling all edge cases.
	- Also, any further logic changes, will be integrable easily, as all test cases need to pass,
	  before pushing the code

	In Unittesting, for each test suite, there will be
		a pair of class methods, called setup and tearDown
		and pair of instance methods, called setup and tearDown

			setup class method 		-- executes at the start of the test suite
			tearDown class method 	--  executes at the end of the test suite

			setup instance method 	-- executes at the start of each test case
			tearDown instance method – executes at end of each test case

	- According to Martin Fowler, creator of unit tests,
		- Dummy objects
			are passed around but never actually used.
			Usually they are just used to fill parameter lists.
		- Fake objects
			actually have working implementations, but usually take some shortcut which
			makes them not suitable for production (an in memory database is a good example).
		- Stubs
			provide canned answers to calls made during the test, usually not responding
			at all to anything outside what's programmed in for the test.
			Stubs may also record information about calls, such as an email gateway stub
			that remembers the messages it 'sent', or maybe only how many messages it 'sent'.
		- Mocks
			are what we are talking about here: objects pre-programmed with expectations
			which form a specification of the calls they are expected to receive.


- name mangling
	- python supports Public, private and protected variables/methods/functions
	- We can access even private variables, methods too  in python,
		But the convention is made to avoid accidental override

	- Variable starting with no _underscores are called public variables
	- Variables starting with single underscore are called protected variables
	- variables starting with two underscores are called private variables
		- Also, variables starting with two underscores and ending with two underscores
		  are magic methods (or dunder/double underscore methods, or special methods).
		- Ex: __init__ is the constructor
			  __del__ is the destructor
			  __enter__ and __exit__ are used for creating custom context managers
			  __iter__ and __next__ are used for creating Iterator objects
			  __str__ and __repr__ are used for string representation of the instances


- Monkey patching is replacing a function/method/class by another at runtime,
   for testing purpses, fixing a bug or otherwise changing behaviour.

- namespaces
	LEGB - Local, Enclosed, Global, Builtin scopes

- py vs pyc
	- py extension files are ordinary python files
	- pyc extension files are python bytecode files,

- PEP 8
	- PEP is abbreviation for Python Enhancement Proposal
	- It deals with the coding style guide
	- It will list the best practices, in coding in python
	- These recommendations include
		- to use 4 spaces, and not tabs , for indentation
		- Use triple quotes for docstrings
		- Wrap lines so that they don’t exceed 79 characters, in each line
		- class names should in camel casing, and all others should be in underscore casing
		- Use Python’s default UTF-8 or ASCII encodings and not any fancy encodings
		- Blank Lines
			- Two blank lines should be both before and after class/method/function definitions.
			- You should use blank lines conservatively within your code to separate groups of functions.
		- One space around the operators
		- Wildcard imports (*) should not be preferred
		- Avoid trailing white-spaces

- Memory Management in python
	- Python has automatic memory management.
	- We have a garbage collector, which will check for any unreferenced objects
	  on a periodically, for each CPU clock cycle, and it will delete them.
	- Reference count is the number of references to an object.
	  When the reference count of an object drops to zero, it is deallocated.

	- we can check the reference count of any value using the sys module, sys.getreferencecount
	- The garbage collector can be controlled using the gc module.

- stack & heap
	- each thread will have its own stack, but all the threads in a process will share
	  the heap.

Heap vs stack
	- Whenever an object is created, it’s always stored in the Heap space, and stack
	memory contains the reference to it.
	- Stack memory only contains local primitive variables and reference variables
	to objects in heap space.
	- Objects stored in the heap are globally accessible whereas stack memory can’t
	be accessed by other threads.
	- Memory management in stack is done in LIFO manner whereas it’s more complex in
	Heap memory because it’s used globally.
	- Stack memory is short-lived whereas heap memory lives from the start till the
	end of application execution.
	- Heap memory is used by all the parts of the application, stack memory is used
	only by one thread of execution.
	- When stack memory is full, Java runtime throws java.lang.StackOverFlowError
	  When heap memory is full, it throws java.lang.OutOfMemoryError: Java Heap Space error.
	- Stack memory is faster than heap memory.

Metaclasses
-----------
	- A metaclass is the class of a class.
	- A class defines how an instance of the class (i.e. an object) behaves
		while a metaclass defines how a class behaves. A class is an instance of a metaclass.

	While in Python you can use arbitrary callables for metaclasses, the better approach is
	to make it an actual class itself.
	type is the usual metaclass in Python.
	type is itself a class, and it is its own type.
	You won't be able to recreate something like type purely in Python, but Python cheats
	a little. To create your own metaclass in Python you really just want to subclass type.

	A metaclass is most commonly used as a class-factory. When you create an object
	by calling the class, Python creates a new class (when it executes the 'class' statement)
	by calling the metaclass.
	Combined with the normal __init__ and __new__ methods, metaclasses therefore allow you to
	do 'extra things' when creating a class, like registering the new class with some registry or replace the class with something else entirely.

	When the class statement is executed, Python first executes the body of the class statement as a normal block of code. The resulting namespace (a dict) holds the attributes of the class-to-be. The metaclass is determined by looking at the baseclasses of the class-to-be (metaclasses are inherited), at the __metaclass__ attribute of the class-to-be (if any) or the __metaclass__ global variable. The metaclass is then called with the name, bases and attributes of the class to instantiate it.

	However, metaclasses actually define the type of a class, not just a factory for it, so you can do much more with them. You can, for instance, define normal methods on the metaclass. These metaclass-methods are like classmethods in that they can be called on the class without an instance, but they are also not like classmethods in that they cannot be called on an instance of the class. type.__subclasses__() is an example of a method on the type metaclass. You can also define the normal 'magic' methods, like __add__, __iter__ and __getattr__, to implement or change how the class behaves.

	Here's an aggregated example of the bits and pieces:

	def make_hook(f):
		"""Decorator to turn 'foo' method into '__foo__'"""
		f.is_hook = 1
		return f

	class MyType(type):
		def __new__(mcls, name, bases, attrs):

			if name.startswith('None'):
				return None

			# Go over attributes and see if they should be renamed.
			newattrs = {}
			for attrname, attrvalue in attrs.iteritems():
				if getattr(attrvalue, 'is_hook', 0):
					newattrs['__%s__' % attrname] = attrvalue
				else:
					newattrs[attrname] = attrvalue

			return super(MyType, mcls).__new__(mcls, name, bases, newattrs)

		def __init__(self, name, bases, attrs):
			super(MyType, self).__init__(name, bases, attrs)

			# classregistry.register(self, self.interfaces)
			print "Would register class %s now." % self

		def __add__(self, other):
			class AutoClass(self, other):
				pass
			return AutoClass
			# Alternatively, to autogenerate the classname as well as the class:
			# return type(self.__name__ + other.__name__, (self, other), {})

		def unregister(self):
			# classregistry.unregister(self)
			print "Would unregister class %s now." % self

	class MyObject:
		__metaclass__ = MyType


	class NoneSample(MyObject):
		pass

	# Will print "NoneType None"
	print type(NoneSample), repr(NoneSample)

	class Example(MyObject):
		def __init__(self, value):
			self.value = value
		@make_hook
		def add(self, other):
			return self.__class__(self.value + other.value)

	# Will unregister the class
	Example.unregister()

	inst = Example(10)
	# Will fail with an AttributeError
	#inst.unregister()

	print inst + inst
	class Sibling(MyObject):
		pass

	ExampleSibling = Example + Sibling
	# ExampleSibling is now a subclass of both Example and Sibling (with no
	# content of its own) although it will believe it's called 'AutoClass'
	print ExampleSibling
	print ExampleSibling.__mro__


Numpy
------
- How are numpy and pandas related
- numpy arrays

Pandas
------
In Pandas,
	I worked on reading csv, excel spreadsheets,
	parsing the content,
	transformations like
		added a new column based on some logic, or
		creating new column based on other columns, or
		cleansing activities like removing null rows, cleaning columns, etc

	finally, dumping the resultant data into csv, excel or, even a db table.

array vs list
	array is homogeneous, meaning all values should be of same type.
	List is heterogenous, means all values may or not may be of same type

array vs dataframe
	numpy arrays are either single or multiple dimensions
	pandas has two things
		1) Series is 1 dimensional
		2) Dataframe is 2 dimensional

	Indexing of numpy arrays are faster than that of dataframe.

- loc vs iloc
	- loc gets rows (or columns) with particular labels from the index.
	- iloc gets rows (or columns) at particular positions in the index (so it only takes integers).

- dataframe index
	- When index is unique, pandas use a hashtable to map key to value O(1).
	- When index is non-unique and sorted, pandas use binary search O(logN),
	  when index is random ordered pandas need to check all the keys in the index O(N).

	- join vs merge
		- join() is used to combine two DataFrames on the index but not on columns
		- merge() is primarily used to specify the columns you wanted to join on, this also supports
		joining on indexes and combination of index and columns.

- find differences between two dataframes
	df1=pd.DataFrame({'A':[1,2,3,3],'B':[2,3,4,4]})
	df2=pd.DataFrame({'A':[1],'B':[2]})

	pd.concat([df1,df2]).drop_duplicates(keep=False)

- dataframe to series
- series to dataframe
- uses of series
- vectorization
multi index pandas
- Feature Engineering
	- technique to create  new features from existing data that could help to gain more
	  insight into the data.
	- pandas.apply() for text extraction
	- pandas.groupby() and transform() for Aggregation Features
	- pandas.value_counts() and apply() for Frequency Encoding

- to read specific columns
	df = pd.read_csv("sample_file.csv", usecols=col_list)

Machine learning Models
========================
1) Supervised Learning
	a) Regression
		- Linear Regression
			- Multiple Linear
			- Polynomial
		- Decision Tree
		- Random Forest
		- Neural Network

	b) Classification
		- Logistic Regression
		- Support Vector Machine
		- Naive Bayes
		- Decision Tree, Random Forest, Neural Network

2) Un-supervised Learning -> Patterns from input data without references to labeled outcomes
	- Clustering ->
		- K-means
		- Hierarchical
		- Mean shift
		- Density based
	- Dimensionality Reduction - process of reducing the dimension of your feature set
		- Feature elimination
		- Feature Extraction
			- Principal Component Analysis


Precision
	indicates the positive prediction made by the model
	It refers to the number of true positives divided by total number of postive predictions


Accurancy Vs precision
	Accurancy tells how many times the ML model was correct overall
	Precision is how good the model is at predicting a sepcific category

spark
pyspark bucketby vs partitionby
pyspark compression parquet
spark splittable compression
sqlContext.setConf("spark.sql.parquet.compression.codec.", "snappy")
How to read large parquet file
map and reduce in big data

High Performance Computing, in python
	- Dask
		- for distributed computing.
		- facilitates running many computations at the same time, either on a single machine or on many separate computers (cluster).
		- Under the hood, Dask breaks a single large data processing job into many smaller tasks, which are then handled by numpy or pandas
		- https://dask.org/
	- Modin
		- designed to parallelize pandas DataFrames by automatically distributing the
		  computation across all of the system’s available CPU cores.
		- Modin simply divides an existing DataFrame into different parts such that each part can be sent to a different CPU core. And to be more precise, Modin partitions the DataFrames across both rows and columns, which makes its parallel processing highly scalable for DataFrames of any size and shape.
		- https://github.com/modin-project/modin
	- vaex — 7k GitHub stars
	- datatable — 1.5k GitHub stars
	- cuDF — ~4.5k GitHub stars
	- pyspark
	- Koalas — ~3k GitHub stars
	- polars — ~5k GitHub stars


Hadoop
======
HDFS
	- means Hadoop Distributed File System
	- architecture - https://hadoop.apache.org/docs/r1.2.1/hdfs_design.html

Hadoop Node types
	1) NameNode
		- It is main node of HDFS; also called master node.
		- It stores meta data in RAM for quick access and track the files across hadoop cluster.
		- If namenode fails, entire HDFC is inaccessible.
		- Namenode tracks all information from files such as
			- which file saved in cluster,
			- access time of file,
			- which user access a file on current time
	2) Secondary Node
		- It helps the primary namenode, and merges the namespaces.
		- It stores data when primary namenode fails, and is used to restart the primary namenode.
		- It requires huge memory for data storing
		- It runs on different machines for memory management;
		- Also, it is checking point of namenode
	3) DataNode
		- It stores actual data of HDFS; also called slave node.
		- No data is affected, even if the data node is failed.
		- As it stores actual data, it is configured with lot of disk space
		- It perform read and write operations as per client request.
		- And, Performance of DataNode are based on NameNode Instuctions.
	4) Checkpoint Node
	5) Backup Node
	6) Job Tracker Node
	7) Task Tracker Node

namenode vs datanode
 - NameNode is the master node in HDFS that manages the file system metadata while
   DataNode is a slave node in HDFS that stores the actual data as instructed by the NameNode.

Datanodes
	- DataNodes are responsible for serving read and write requests from the file system's clients.
	- DataNodes also perform block creation, deletion, and replication upon instruction from the NameNode.

master vs datanode
	- Data nodes store the data, and participate in the cluster's indexing and search capabilities, while
	- master nodes are responsible for managing the cluster's activities and storing the cluster state, including the metadata.

jobtracker vs tasktracker
- JobTracker is the service within Hadoop that is responsible for taking client requests.
- It assigns them to TaskTrackers on DataNodes where the data required is locally present.
- If that is not possible, JobTracker tries to assign the tasks to TaskTrackers within the
  same rack where the data is locally present.

=======================================================================
Q1) Describe truthy vs falsy
Ans) Python supports boolean type: True, False

bool() -- builtin function which will result the boolean-ness of the object in it.

For integers,
	0 			-> False
	non-zero 	-> True
For floats,
	0.0			-> False
	non-zero	-> True
	0.000001    -> True

For None		-> False

For boolean
	False		-> False
	True 		-> True

For empty collections,
	empty list 	[] 		-> False
	empty tuple () 		-> False
	empty set   set()	-> False
	empty dict 	{}		-> False

	with atleast one element, it is True

For relational and logical operations, based on result
	logical and --> will result in True, if all are True ONLY, else False
	logical OR  --> will result in False, if all are False ONLY, else True

Q2) How do you get the last item of a list?
Ans) we can use the reverse index to retrieve the last element from the list

 Ex: mylist = [23, 45,  6,  3, 23, 65,  2,   4]
			   0   1    2   3   4   5   6     7  <----- forward indexing
			   -8  -7  -6  -5  -4  -3  -2    -1  <------ reverse indexing

	lastnum = mylist[-1]

	Also, we can get indirectly (not preferred) by
		lastNum = mylist[len(mylist) - 1]

Q3) What does a leading _ (underscore) before a variable typically identify in python (used as a common naming convention)?
Ans) Python follows naming convention called name mangling for the variables/methods

	name 	-> Public variable  	- no leading underscores - can be accessed directly
	_name	-> Protected variables  - one leading underscore - can be accessed directly
	__name	-> Private variables 	- two leading underscores - prepend class name as protected variable before it to access
										Ex: _ClassName__name

	__name__ -> built-in variables, or dunder methods, or magic methods
				there are some specific methods, as such.

What is a magic method ( aka dunder method)?
Ans)
These are the builtin methods with some specific usage
As they start and end with two (double) underscores, they were called as dunder (double-underscore) methods.
Examples:
	__init__		constructor method - responsible for added default actions, after creating instance
	__del__			destructor method  - will invoke when deleting the instance
	__new__			method responsible for creating the instance, from a class

	__slot__				will restrict the attributes of class instance

	__enter__ & __exit__ 	used for creating custom context managers

	__iter__ & __next__ 	used for creating custom iterator classes


Also, if we create the class methods with dundermethods like __add__, then
with the instances, instead of addressing with this method names like

	instance1.__add__(instance2)

we can also do as below
	instance1 + instance2


Q4) What was introduced in python 3.6 that changed string formatting?
What do you prefer: f-string or .format()?
Ans)  String formattings in python
	- old style formatting  - using % with the specific data types
		Ex: language = "%s is rank %d language " %("python", 1)


	- new style formatting - using format() with placeholders, and not specific on data types
		Ex: language = "{0} is rank {1} language ".format("python", 1)

	- F-strings (from python 3.6)  -- advanced formatting
		Ex:
			lang = "python"
			rank = 1
			language = f"{lang} is rank {rank} language "

		Also, we can do computations within the braces to do more operations

			language = f"{lang.upper()} is rank {float(rank)} language "

	- F-string assignments ( from python 3.8)
		it will help in the debugging results.
		Instead of
			print("langauge = ", language)
			print("langauge = %s"% language)
			print("langauge = {}".format(language))
			print(f"langauge = {language}")

		we can write as
			print(f"{language =}"

Finally, among the three (old-style, new-style with format() and f-strings), the
F-string based formatting with take the least amount of time.

So, i prefer F-strings among all.


big data
	mapper - producer
	reduce - receiver

Python Programming
==================
1) Give some examples of data types in python?
Ans)Basic Data types 			- Int, Float, String, None, Bool
	Built-in Data Structures 	- List, Tuple, Set, Dictionary

2) What is the difference between a list and a tuple?
Ans)List is mutable object, means we can edit the object like append, delete, ..
	where as tuple is immutable
	Tuples are faster than lists
		- Tuples are stored in a single block of memory. Tuples are immutable so,
		It doesn't require extra space to store new objects.
		- Lists are allocated in two blocks:
			1. fixed one with all the Python object information, and
			2. variable sized block for the data.
	- USAGE:
		List is used when we need to make changes in code, say adding values while loop .
		Tuple is used when we wont change something in the code

3) When is it a good idea to use a dictionary
Ans)Dictionary is good when there are more reads than writes.
	For reading a key in dict, it is O(1) as keys are unique (hashed and stored).

4) What is a lambda function and why would you use it
Ans)It is a one liner function, mainly useful for evaluating a single expression that is supposed to be evaluated only once.
	- SYNTAX is lambda arguments: expression
	- We need not define a complete function. We can use it instantly for the purpose.
	- It can be passed as a parameter to a higher-order function, like filter(),
	map(), and reduce().
	- example
		- if we have to increment all values in a list by one,
				map(lambda x:x + 1, range(10))
	- And, coming to the con side,
		- It can’t perform multiple expressions.
		- It can easily become cumbersome, for example when it includes an if-elif-else cycle.
		- It can’t contain any variable assignments (e.g., lambda x: x=0 will throw a SyntaxError).
		- We can’t provide a docstring to a lambda function.

5) How to get the last character in a string
Ans) Using the negative index, we can get.
	Ex:word = "Hello"
		last_char = word[-1]

6) What structure do you use to handle an exception (bonus: when does an else block get executed)?
Ans)In Python, exception handling has FOUR blocks. Else and Finally blocks were optional.
	1) Try --- executed every time
	2) Except--- executed when there is exception in try block, check if it can handle break code if it cant
	3) Else--- executed when no exception in try block
	4) Finally-- executed every time— irrespective of failure, it is like for file closing, etc ….

7) What is the difference between a class and an object?
Ans)The instances of class are called objects.
	Class defines the properties and behavior of its instances.
	We can create instances from all classes, except the abstract classes.

8) How would you break apart a comma-delimited list, then put it back together?
Ans) Hoping the question is comma-delimited string. if so,
	Ex: mystr = "a,b,c,d,1,2"
		chars = mystr.split(',') # splits the string to list of chars
		joined = ','.join(chars) # joining the list of strings, to a single string, with again comma as the delimiter

9) How to denote a comment in python?
Ans) Unlike many languages (like java, c++, ...), python dont have multiple comments, as it is an interpreter based language,
where only one line of code is processed by the interpreter each time. Python has only line comments, with # (hash/pound) operator.
It will have its effect from the place it is defined, till the end of that line. This operator will be treated as ordinary character,
if it is part of any string.

10) When would you use the keyword self?
Ans)self acts as a placeholder of the instance, being passed to the class.
	It is not a python keyword, but PEP 8 recommends using it.

Networking( only answer this if you have experience in this area)
======================================================================
1) Give me an example of a layer 4 protocol
Ans) In the OSI model, layer 4 protocol example include
		UDP - User Datagram Protocol
		TCP - Transmission Control Protocol

2) Give me an example of a layer 7 protocol
Ans)Layer 7 protocol examples include
		HTTP - HyperText Transfer Protocol - for internet communication
		SMTP - Simple Mail Transfer Protocol - for email communication

3) There are two parts of an HTTP request the headers and body, what are some examples of headers found in an HTTP request
Ans) A typical HTTP request header contains,
		HTTP Method, URL and HTTP version
		Host 		- server FQDN name
		User-Agent 	- Source (browser or program based) of the request
		Accept 		- What types of data is accepted
		Accept-Language - language of communication
		Accept-Encoding - Types of encoding supported
		Connection	 - connection type - keep-alive or closed
		Cache-Control- If cache present, the age of cache. If default, max-age=0

4) What is the difference between HTTP and HTTPS?
Ans)HTTP with encryption is called HTTPS.
	HTTPS uses TLS (earlier SSL) to encrypt normal HTTP requests and responses.
	So, HTTPS is more secure than HTTP.

5) What tool can be used to snoop on network traffic reaching the local machine
Ans) WireShark, TCPDump and WinDump are the most commonly used sniffing tools.
	I worked with wireshark, which gives the .pcap files. I analyzed them programmatically to pull insights.

6) Describe the steps of a TLS handshake (advanced)
Ans) TLS came as a replacement for SSL.
	SSL - Secure Sockets Layer
	TLS - Transport Layer Security

	During the TLS handshake, the client and server together will decide on the TLS version, the cipher which suits both.
	Authenticate the identity of the server via the server's public key and the SSL certificate authority's digital signature.
	Generate session keys in order to use symmetric encryption after the handshake is complete

	The RSA key exchange algorithm is the most common way for the TLS handshake.
	In RSA Key exchange,
		1) Client initiates handshake by sending a hello message, containing
			TLS version the client supports
			cipher suites supported
			string of random bytes, called client random
		2) Server replies with message containing
			the server's SSL certificate,
			the server's chosen cipher suite,
			another string of random bytes, called server random
		3) Client verifies the server's SSL certificate with certificate authority that issued it.
		4) Once verified, the client sends one more random string of bytes, called premaster secret.
		 This premaster secret is encrypted with a public key(which it got from SSL certificate)
		 and can only be decrypted with a private key by the server.
		5) The server decrypts the premaster secret with its private key
		6) Both client and server generate session keys from the client random, server random and the premaster secret.
		 Both results should be the same.
		7) Client sends a "finished" message that is encrypted with a session key.
		8) Server sends a "finished" message encrypted with a session key.
		9) The handshake is completed, and communication continues using the session keys.


Communication/Process
======================
1) Describe your understanding of the scrum process
Ans) It is a project management system. There are two types:
	a) Agile scrum methodology works on incremental development.
			There will be sprint planning, where we plan what to do in the next sprint
			We have a sprint for 2 weeks, in general.
			We have daily standup calls, where we discuss the progress of these jiras, and any blockers.
			At the end of the sprint, we have sprint reviews and retrospective calls.
	b) Kanban
			It is suitable for bug management , mainly.
			Each ticket has a specific weightage and it will go as per this SLA.

2) What is your communication style when chatting on slack
Ans) I will try to explain the point, to avoid ambiguity. For Example, If i am struggling with a problem
	a) I will try to precisely explain the problem
	b) Then, I will list out the different ways of addressing the problem, and corresponding results/failures.
	c) If i have any thoughts, i will ask to suggest among them.

	When someone replies, we will proceed, point-to-point reply
