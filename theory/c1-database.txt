DB Experience
=============
- I didnt work on database administration, but with development work only
- As a developer, I worked with all kinds of features, except managing the databases
- In terms of features, I worked with
	database design
	creating tables and establishing relations
	creating db triggers, db views, indexing, SQL procs, etc

Data Sources
	- both internal and external to the organization
	- worked wih REST API, both paginated and streaming API
		- as part of connecting with them, worked on Authentication mechanisms like Oauth, JWT, etc.
	- Also, connected with internal database; and graphQL too.
	- Also, in terms of file formats, worked with structured (like csv, tsv, parquet, json, ..), unstructured and semi-structured files.

- Modules worked with databases
	- For ORM - Sqlalchemy, and for django - using django ORM
	- Modules
		- pymysql for working with MySQL db
		- pyodbc for working with MS-SQL db
		- cx_oracle for working with Oracle db
		- psycopg2 for working with postgres
		- pymongo for working with MongoDB

- ORM
	- means Object Relational Mapper
	- ORMS will help in performing db queries and manipulations using Object Oriented way.
	- Means writing quries in programming language, like python, instead of in raw SQL.
	- Advantages
		- Less code, so more productivity and easier maintenance.
		- Database type agnostic, means later we can change db from, say, mysql to MS-SQL, and
		  the written ORM will work.
		- Sanitization of queries, mainly, helps in avoiding security issues like SQL injection attacks.

	- Disadvantages
		- It involves some learnings, for each ORM.
		- ORMs will be difficult to read and maintain when we have, say, like 5 or more tables in JOIN
		- Also, for large queries, it is be slower too.

- SQL solutions - https://javarevisited.blogspot.com/2017/02/top-6-sql-query-interview-questions-and-answers.html#axzz7f7DekILS
- https://www.interviewbit.com/sql-interview-questions

- Relational Databases
	- row oriented
		- Eg: Mysql, postgre
		- Organizes data records row by row
		- these are write optimized
		- suitable for OLTP (online transactional processing) style applications
		  as they can manage writes to the database well.
		- Fast at retrieving a row or a set of rows but when performing an aggregation
		  it brings extra data (columns) into memory which is slower than only selecting
		  the columns that you are performing the aggregation on.
		- And the number of disks the row oriented database might need to access
		  is usually larger.
	- column oriented / columnar or C-store databases
		- Eg: RedShift, BigQuery, snowflake
		- Organizes data by field, keeping all of the data associated with a field
		  next to each other
		- these are read-optimized
		- suitable for OLAP (online Analytics Processing) style applications
		  as they support adhoc querying the data
- ACID
	- Atomicity
		- There should not be any partially completed transaction;
		- Either it should be completed applied or rolled back.

	- Consistency
		- characteristic that requires data updated via transactions to respect the other
		  constraints or rules within the database systems to keep data in a consistent state

	- Isolation
		- Modification of one transactions, should not effect other transactions.
		- parallel transactions are in reality isolated and seem to be performed sequentially.

	- Durability
		- persistence of committed transactions.
		- Transactions and database modifications are not kept in volatile memory but
		  are saved to permanent storage, such as disks.
		- This prevents data loss during system failure, such as a power outage.

- DDL commands
	CREATE	: Create an object. ...
	DROP 	: This SQL DDL command helps to delete objects. ...
	ALTER 	: Used to alter the existing database or its object structures.
	TRUNCATE: This SQL DDL command removes records from tables.
	RENAME 	: Renaming the database objects.

- DML commands
	INSERT 		: It is used to insert data into a table.
	UPDATE		: It is used to update existing data within a table.
	DELETE 		: It is used to delete records from a database table.
	LOCK		: Table control concurrency.
	CALL		: Call a PL/SQL or JAVA subprogram.
	EXPLAIN PLAN: It describes the access path to data.

- Order of Execution
	- From, Where, Group By, Having, Select, Order By, Limit

- Order in Commands
	- Select, From , JOIN(ON), Where, Group BY, Having, Order By, Limit


- SQL JOINs
	- https://insightoriel.com/what-is-join-in-sql/
	- Four types -  left, right, inner, and outer.
	- (INNER) JOIN 		 : Returns records that have matching values in both tables.
	- LEFT (OUTER) JOIN  : Returns all records from the left table, and the matched
						   records from the right table.
	- RIGHT (OUTER) JOIN : Returns all records from the right table, and the matched
						   records from the left table.
	- CROSS JOIN 		 : there is no ON clause here. All rows from the first table
						   are combined with all rows from the second table.

			SELECT w.name AS wine, m.name AS main_course
			FROM wine w
			CROSS JOIN main_course m;

	- FULL OUTER JOIN
		-- MySql FULL OUTER JOIN

				SELECT * FROM t1
				LEFT JOIN t2 ON t1.id = t2.id
				UNION ALL
				SELECT * FROM t1
				RIGHT JOIN t2 ON t1.id = t2.id
				WHERE t1.id IS NULL

	- number of records in each JOIN
		TableA - 10 rows
		TableB - 20 rows

		CROSS JOIN -- 10 * 20 = 200 rows

		Left joins can increase the number of rows in the left table if there are multiple
		matches in the right table.
		Left joins can increase the number of rows in the left table if there are multiple
		matches in the right table.
	- cartesian product - select * from employees, departments


- Normalization
	- process of organizing the columns, tables of a database to minimize the
		redundancy of data. Normalization involves in dividing large tables
		into smaller tables and defining relationships between them.
	- First Normal Form:
		Duplicate columns from the same table needs to be eliminated.
		We have to create separate tables for each group of related data and
		identify each row with a unique column or set of columns (Primary Key)
	- Second Normal Form:
		First it should meet the requirement of first normal form.
		Removes the subsets of data that apply to multiple rows of a table and
		place them in separate tables.
		Relationships must be created between the new tables and their predecessors
		through the use of foreign keys.
	- Third Normal Form:
		First it should meet the requirements of second normal form.
		Remove columns that are not depending upon the primary key.
		- Most databases will be Third Normal Form
	- Fourth Normal Form:
		- There should not be any multi-valued dependencies.

- Relations
	- one-to-one relationship
		- simple reference between two tables. Consider Customer and Address tables
		as an example.
		- A customer can have only one address and an address references only one customer.
	- One-to-many relationships
		- Implemented by splitting the data into two tables with a primary key and
			foreign key relationship.
		- Here the row in one table is referenced by one or more rows in the other table.
		An example is the Employees and Departments table, where the row in the Departments
		table is referenced by one or more rows in the Employees table.
	- Many-to-Many relationship
		- created between two tables by creating a junction table with the key from both
		the tables forming the composite primary key of the junction table.

-  Truncate vs Delete
	- Both used to delete data from the table
	- Truncate is a DDL statement. Delete is a DML statement
	- Truncate does not generate rollback segments. Whereas Delete does.
	- In case of delete, rollback recovers data before issuing a commit.
		In case of truncate, you cannot recover data.
	- Truncate does not fire any delete triggers created on the table.
		Whereas the delete does.

- DELETE
	- DML COMMAND
	- Delete Rows from the table one by one
	- We can use where clause with Delete to delete single row
	- Delete is slower than truncate
	- ROLLBACK is possible with DELETE

- DROP
	- DDL COMMAND
	- Delete the entire structure or schema
	- We can't use where clause with drop
	- Drop is slower than DELETE & TRUNCATE
	- ROLLBACK IS NOT POSSIBLE WITH DROP

- TRUNCATE
	- DDL COMMAND
	- Truncate deletes rows at a one goal
	- We can't use where clause with Truncate
	- Truncate faster than both DELETE & DROP
	- Rollback is not possible with Truncate

- Union vs Union all
	- Union set operator removes duplicate records. Whereas union all does not.
	- Union operator sorts the data in ascending order. union all does not.
	- Union all is faster than union operator.

- Intersect vs Except
	- INTERSECT: Takes the data from both result sets which are in common.
	- EXCEPT: Takes the data from the first result set, but not in the second
			  result set (i.e. no matching to each other)
- keys
	- Primary key:
		- used to uniquely identify each row in a table and does not allow null values.
		- composite primary key
			- combination of multiple columns, to make the primary key
	- Foreign key:
		- it is one or more columns whose values are based on the primary key values
		from another table.
	- Unique Key:
		- Unique key identifies a each row in the table uniquely.
		- Unique key allows null values.

- stored procedure vs Functions
	- procedure allows SELECT as well as DML(INSERT/UPDATE/DELETE) statement in it
	  whereas Function allows only SELECT statement in it.
	- Procedures cannot be utilized in a SELECT statement whereas Function can be
	  embedded in a SELECT statement.
	- Stored Procedures cannot be used in the SQL statements anywhere in the
	  WHERE/HAVING/SELECT section whereas Function can be.
	- An exception can be handled by try-catch block in a Procedure whereas
	  try-catch block cannot be used in a Function.
	- stored procs neither contain any parameter, nor return any value.
	  Functions should contain atleast one parameter and should return a value.
	- functions can be called from stored procs; but cant call stored procs from functions.
	- Transactions and DML commands can be executed on stored procs; but not with functions.

- stored procedure vs db triggers
	- Trigger is a procedure invoked automatically when certain db events(like create/delete record) occurs.
	  Stored Procedure is a procedure that is explicitly invoked by either
		- another client application
		- or another stored procdure
		- or another trigger procedure
	- Also, Stored procedures can accept parameters  and can return values, whereas
	  triggers can neither accept parameters nor return values.
	- And, transaction statements cant be used inside a trigger; whereas transaction statements
	  like begin transaction, commit transaction and rollback, can be used in stored procedures.


- SubQuery properties
	- A sub-query must be enclosed in the parenthesis.
	- A sub-query must be put in the right hand of the comparison operator, and
	- A sub-query cannot contain an ORDER-BY clause.
	- A query can contain more than one sub-query.
	- Types
		- Single-row sub-query, where the sub-query returns only one row.
		- Multiple-row sub-query, where the sub-query returns multiple rows,. and
		- Multiple column sub-query, where the sub-query returns multiple columns.

- COALESCE
	- it will return the first non-null value, in the column

- Cursor
	- Used when application logic need to work with one row at a time, rather than entire result at once.
	- Advatanges
		- Cursors provide first few rows before the whoel result set is assembled.
		  so, better response time is achived, compared to traditional queries, without cursor.
	- Limitations
		- Uses more resource because each time you fetch a row from cursor, it results in
		  a network roundtrip.
		- Because of the round trips, performance and speed is slow

	- Alternatively, we can use JOIN to retrieve the data much fastly

- DB Indexing
	- Clustered
		- sort and store the data rows in the table, or view based on their key values.
		- index contains pointers to block, but not direct data.
		- Ex:if primary key is applied to any column, it automatically becomes clustered index.
		- You can have only one clustered index in one table, but you can have one clustered
		  index on multiple columns, and that type of index is called composite index.
		- faster and requires less memory for operations
	- Non-clustered
		- The data is stored in one place, and index is stored in another place.
		  Since, the data and non-clustered index is stored separately, then you can have
		  multiple non-clustered index in a table.
		- In non-clustered index, index contains the pointer to data.
		- slow and requires more memory for operations

- physical index vs logical index
	- physical index is the actual indexing structure as it is stored on disk.
	- logical index is a reference to a physical index.

	- When we create a primary key, secondary key, foreign key, or unique constraint, the
	  database server ensures referential integrity by creating a logical index for the constraint.

- Sharding
	- It is a technique that splits data into separate rows and columns held on separate database
	server instances in order to distribute the traffic load.
	- Each small table is called a shard.
	• Sharding key: a specific column value that indicates which shard this row is stored in.
	• Sharding algorithm: an algorithm to distribute your data to one or more shards.

- window functions
	- window functions operate on a set of rows and return a single aggregated value for each row.
	- Unlike regular aggregate functions, window functions retuns single aggregated value for each row.
	- There are 3 types of window functions
		- Aggregate window functions - SUM(), MAX(), MIN(), AVG(), COUNT()
		- Analytical window functions
			- Ranking Window Functions - RANK(), DENSE_RANK(), ROW_NUMBER(), NTILE()
					ROW_NUMBER() -- 1,2,3,4,5 (different rank no. to same value)
					RANK() 		 -- 1,2,2,4,5 (same rank no. to same value but next rank is skipped)
					DENSE_RANK() -- 1,2,2,3,4 (same rank no. to same value but no skip in rank no.)

					ROW_NUMBER()
						- generates incremental row number dynamically, for each row, based on given order
							Ex: ROW_NUMBER() OVER (ORDER BY marks) as row_num
						- If partition by clause is added, the sequencing will be for each of the partition
							Ex: ROW_NUMBER() OVER (PARTITION BY dept_name ORDER BY marks) as row_num

			- Value Window Functions - LAG(), LEAD(), FIRST_VALUE(), LAST_VALUE()

- SQL constraints
	NOT NULL 	 # Ensures a column cannot have a NULL value
	UNIQUE 		 # Ensures all values in a column are unique
	PRIMARY KEY  # Identifies a record in a table, is NOT NULL & UNIQUE
	FOREIGN KEY  # References a unique record from another table
	CHECK		 # Ensures all column values satisfy a condition
	DEFAULT		 # Set a default value for a column if none is entered
	INDEX		 # Quick way of retrieving records from database


- temp tables
	- Table variables (DECLARE @t TABLE) are visible only to the connection that creates it,
					and are deleted when the batch or stored procedure ends.
	- Local temporary tables (CREATE TABLE #t) are visible only to the connection that creates it,
					and are deleted when the connection is closed.
	- Global temporary tables (CREATE TABLE ##t) are visible to everyone, and are deleted when all
					connections that have referenced them have closed.
	- Tempdb permanent tables (USE tempdb CREATE TABLE t) are visible to everyone, and are deleted
					when the server is restarted.

- CTE
	- means Common Table Expressions
	- It is a temporary named result set that can be referenced within a SELECT, INSERT, UPDATE or DELETE statements.
	- CTEs can also be used as views.
	- CTE's members cannot use the clauses of keywords like Distinct, Group By, Having, Top,
	  Joins limiting by this type of the queries that can be created and reducing their complexity.

	-Example
		WITH
		odd_num_cte (id, n) AS
		(
			SELECT 1, 1
			UNION ALL
			SELECT id+1, n+2 from odd_num_cte where id < 5
		)
		SELECT * FROM odd_num_cte;


- DB view vs CTE
	- CTE cannot be nested while Views can be nested.
	- View once declared can be used for any number of times but CTE cannot be used.
	It should be declared every time you want to use it.


- DB View vs Materialized View
	DB Views					Materialized DB Views
	------------------------------------------------------------------------------------------------------
	Virtual table and doesn’t occupy any storage space	Copies of data are stored in the memory
	It will have up to date data in it as it is executed at run-time	Needs to be refreshed every time when it is used as it has compiled data
	Executed when a query is run n view using SELECT	Executed and records are stored in the database
	Data access is slower	 Faster data access because data is directly accessed from physical location
	Generally, used to restrict data from database	Generally, used in data warehousing

- DB Triggers
	- they are kind of stored procedures, which reacts to certain actions we make in db.
	- actions like creating/updating/deleting a record
	- 3 groups
		- DML (data manipulation language) triggers react to INSERT, UPDATE, and DELETE
		- DDL (data definition language) triggers react to  CREATE, ALTER, and DROP
		- Logon triggers reacts to LOGON events
	ref: https://www.sqlshack.com/learn-sql-sql-triggers/

- row-store vs column-store
	- row store
		- easy to add/modify a record
		- might read in unnecessary data
	- column-store
		- only need to read in relevant data
		- tuple writes require multiple accesses
		- suitable for read-mostly, read-intensive, large repositories

- MongoDB - https:
	- cheatography.com/zeineb-and-kawther/cheat-sheets/mongodb/

		SQL						|    NoSQL
		  relational			| non-relational
								|
		use structured query	| NoSQL databases have
		language and have a		| dynamic schemas for
		predefined schema.		| unstructured data.
								|
		are vertically scalable | are horizontally scalable.
		are table based			| are document, key-value,
								| graph or wide-column stores.
- SQL vs no-SQL
	- Mainly sql has schema, where as nosql doesnt have it.
	- SQL
		- Data is stored in tables with mutable but pre-defined Columns. Records are stored
		  as Rows in these tables.
		- Implements the ACID database model, which basically means it favours consistency over
		  availability.
		- Scalability is mainly achieved by increasing the resources on the host, usually this
		  means more cpu, memory, storage or network capacity(vertically scalable).
	- NoSQL
		- Data can be stored as documents, key-value pairs, tables and graphs.
		- Implements the BASE database model, which basically means it favours availability
		  over consistency.
		- Scalability is mainly achieved by spreading datasets across multiple servers.(horizontally scalable)

- BASE model
	- Basically Available
		– Rather than enforcing immediate consistency, BASE-modelled NoSQL databases will
		  ensure availability of data by spreading and replicating it across the nodes of
		  the database cluster.
	- Soft State
		– Due to the lack of immediate consistency, data values may change over time.
		- The BASE model breaks off with the concept of a database which enforces its own
		  consistency, delegating that responsibility to developers.
	- Eventually Consistent
		– The fact that BASE does not enforce immediate consistency does not mean that it
		  never achieves it.
		- However, until it does, data reads are still possible (even though they might
		  not reflect the reality).


Good database design is driven by several core principles:
Minimize redundancy: To save resources, create an efficient database, and simplify how the database works, data redundancy is minimized and duplication is avoided.
Protect accuracy: Your database should keep information accurate and reduce the likelihood of accidentally damaging information.
Be accessible: The business intelligence systems that need reading and writing access should have it. Your database should provide access while also protecting data security.
Meet expectations: Of course, you keep a database to fulfill a specific purpose—so the database design must successfully support your data processing expectations.


- SQL performance Tuning
	1. Use EXISTS instead of IN to check the existence of data.
	2. Avoid * in the SELECT statement. Give the name of the columns which you require.
	3. Choose appropriate Data Type. E.g. To store strings use varchar in place of text data type. Use text data type,
	   whenever you need to store large data (more than 8000 characters).
	4. Avoid nchar and nvarchar if possible since both the data types take just double memory as char and varchar.
	5. Avoid NULL in fixed-length field. In case of requirement of NULL, use variable-length (varchar) field that takes less space for NULL.
	6. Avoid Having Clause. Having clause is required if you further wish to filter the result of an aggregations.
	7. Create Clustered and Non-Clustered Indexes.
	8. Keep clustered index small since the fields used in clustered index may also used in non-clustered index.
	9. Most selective columns should be placed leftmost in the key of a non-clustered index.
	10. Drop unused Indexes.
	11. Better to create indexes on columns that have integer values instead of characters. Integer values use less overhead than character values.
	12. Use joins instead of sub-queries.
	13. Use WHERE expressions to limit the size of result tables that are created with joins.
	14. Use TABLOCKX while inserting into a table and TABLOCK while merging.
	15. Use WITH (NOLOCK) while querying the data from any table.
	16. Use SET NOCOUNT ON and use TRY- CATCH to avoid deadlock condition.
	17. Avoid Cursors since cursor are very slow in performance.
	18. Use Table variable in place of Temp table. Use of Temp tables required interaction with TempDb database which is a time taking task.
	19. Use UNION ALL in place of UNION if possible.
	20. Use Schema name before SQL objects name.
	21. Use Stored Procedure for frequently used data and more complex queries.
	22. Keep transaction as small as possible since transaction lock the processing tables data and may results into deadlocks.
	23. Avoid prefix “sp_” with user defined stored procedure name because SQL server first search the user defined procedure in the master database and after that in the current session database.
	24. Avoid use of Non-correlated Scalar Sub Query. Use this query as a separate query instead of part of the main query and store the output in a variable, which can be referred to in the main query or later part of the batch.
	25. Avoid Multi-statement Table Valued Functions (TVFs). Multi-statement TVFs are more costly than inline TVFs.

- SQL performance of inserts
	1) Remove all triggers and constraints on the table
	2) Remove all indexes, except for those needed by the insert
	3) Ensure your clustered index is such that new records will always be inserted at the end of the table
	 (an identity column will do just fine). This prevents page splits (where SQL Server must move data around because an existing page is full)
	4) Set the fill factor to 0 or 100 (they are equivalent) so that no space in the table is left empty, reducing the number of pages that the data is spread across.
	5) Change the recovery model of the database to Simple, reducing the overhead for the transaction log.

- rank vs dense rank
	views vs materialized views
	stored procedures

- User-defined Functions Vs Stored Procedures
	- The function must return a value but in Stored Procedure it is optional. Even a procedure can return zero or n values.
	- Functions can have only input parameters for it whereas Procedures can have input or output parameters.
	- Functions can be called from Procedure whereas Procedures cannot be called from a Function.

- sql subquery properties
	- A subquery should be placed within the right hand of the comparison operator, and
	  a subquery cannot contain an ORDER BY clause.
	- A query can contain more than one sub-queries.

Characteristics of MySQL:
	- Database locking (MUCH easier for financial transactions)
	- Consistency/security (as above, you can guarantee that, for instance, no changes happen between the time you read a bank account balance and you update it).
	- Data organization/refactoring (you can have disorganized data anywhere, but MySQL is better with tables that represent "types" or "components" and then combining them into queries -- this is called normalization).
	- MySQL (and relational databases) are more well suited for arbitrary datasets and requirements common in AGILE software projects.

	- Two db engines
		- MyISAM - My Indexed Sequential Access Method
			- used for web, data warehousing and other analytic environments
	- InnoDB vs MyISAM
		- InnoDB has row-level locking; MyISAM only has full table level locking
		- InnoDB supports transactions, means we can commit and rollback
		  MyISAM is faster to read
		- InnoDB supports foreign keys and relationship constraints(referential integrity),
		  where as MyISAM doesnt support.
		- InnoDB supports caching both data and indexes, but doesnt support full-text search.
		  MyISAM is only meant for indexes, and full-text search.
		- InnoDB supports transaction logs and data recovery on failure; whereas MyISAM doesnt.

Characteristics of Cassandra:
	- Speed: For simple retrieval of large documents. However, it will require multiple queries for highly relational data – and "by default" these queries may not be consistent (and the dataset can change between these queries).
	- Availability: The opposite of "consistency". Data is always available, regardless of being 100% "correct".[1]
	- Optional fields (wide columns): This CAN be done in MySQL with meta tables etc., but it's for-free and by-default in Cassandra.

Postgresql
==========
data types
	Boolean
	Character Types [ such as char, varchar, and text]
	Numeric Types [ such as integer and floating-point number]
	Temporal Types [ such as date, time, timestamp, and interval]
	UUID [ for storing UUID (Universally Unique Identifiers) ]
	Array [ for storing array strings, numbers, etc.]
	JSON [ stores JSON data]
	hstore [ stores key-value pair]
	Special Types [ such as network address and geometric data]

INITCAP()
	make the first letter of each word uppercase and the rest of the letters lowercase.

type Conversion
	1) using CAST ( expression AS target_type );
			CAST ('100' AS INTEGER);
			CAST ('2015-01-01' AS DATE),
			CAST ('01-OCT-2015' AS DATE);
			CAST ('10.2' AS DOUBLE PRECISION);
			CAST('true' AS BOOLEAN),
			CAST('false' as BOOLEAN),
			CAST('T' as BOOLEAN),
			CAST('F' as BOOLEAN);

	2) using expression::type
			'100'::INTEGER,
			'01-OCT-2015'::DATE;
			'2019-06-15 14:30:20'::timestamp;
			'15 minute'::interval,
			'2 hour'::interval,
			'1 day'::interval,
			'2 week'::interval,
			'3 month'::interval;

TRIM
	LTRIM() function removes all characters, spaces by default, from the beginning of a string.
	RTRIM() function removes all characters, spaces by default, from the end of a string.
	BTRIM function is the combination of the LTRIM() and RTRIM() functions.

	Syntax:
		TRIM(LEADING character FROM string); -- LTRIM(string,character)
		TRIM(TRAILING character FROM string); -- RTRIM(string,character)
		TRIM(BOTH character FROM string); -- BTRIM(string,character)

	REGEX_REPLACE
		SELECT REGEXP_REPLACE('enterprise 	', '\s+$', '');

postgresql string functions - https://www.w3resource.com/PostgreSQL/introduction-to-postgresql-string-functions.php

MongoDb
=======
	// Join in mongoDB

	// Customer table
	db.customer.insertMany(
		[
			{ "name": "Abhishek", "age": 50, "address": "f/403 anurag", productId: 1 },
			{ "name": "raj", "age": 30, "address": "302 Neelmani", productId: 2 },
			{ "name": "simran", "age": 70, "address": "rajkot", productId: 3 },
			{ "name": "Dhruval", "age": 60, "address": "chennai", productId: 4 }
		]
	)

	// Product table
	db.product.insertMany(
		[
			{ "product_name": "Abhishek", prod_id: 2, "price": 300 },
			{ "product_name": "raj", prod_id: 3, "price": 500 },
			{ "product_name": "simran", prod_id: 1, "price": 400 },
			{ "product_name": "Dhruval", prod_id: 4, "price": 1000 }
		]
	)

	// Join using lookUp
	db.customer.aggregate([
		{
			$lookup:
			{
				from: "product",
				localField: "productId",
				foreignField: "prod_id",
				as: "productReference"
			}
		}
	])

GraphQL
=======
- resolver
	- It is a function that's responsible for populating the data for a single field in your schema.
	- It can populate that data in any way you define, such as by fetching data from a back-end
	  database or a third-party API.


Lazy Loading
	- it is the practice of delaying load or initialization of resources or objects until
	  they're actually needed to improve performance ans save system resources.
	- Advantages include,
		- Reduced initial load times
		- Bandwidth conservation
		- System resource conservation

Eager Loading
	- it is the preloading more than needed.


Neo4j vs mongoDB
================
- Primary database model is Graph DBMS for Neo4j; where as it is document store for MongoDB
- Unlike MongoDB, Neo4j has foreign keys
- MongoDB supports Map Reduce method, whereas Neo4j wil not
- MongoDB data is schema free; whereas schema is optional in Neo4j
- Neo4j doesnt support SQL queries; whereas MongoDB supports standard SQL queries to Read-Only SQL queries
  via the MongoDB Connector for BI
- Neo4j doesnt support Partitioning; whereas MongodB supports sharding partitionining methods.


SQL Alchemy Loading - https://docs.sqlalchemy.org/en/14/orm/loading_relationships.html

- Logical DB Design Tools
	1) Visual Paradigm ERD Tools
	2) Vertabelo
	3) Lucidchart
	4) SQL Server Database Modeler
	5) DeZign for Databases
	6) Erwin Data Modeler
	7) Aqua Data Studio ER Modeler
	8) DbWrench
	9) IBM InfoSphere Data Architect
	10) DbDesigner.net
	11) dModelAid
	12) dbdiagram.io
	13) Diagrams.net (formerly Draw.io)
	14) QuickDBD
	15) ERD Plus

- Data Warehouse
	- https://aws.amazon.com/data-warehouse/
	- single, complete and consistent store of data obtained from
	  a variety of different sources made available to end users

	OLAP -- for  application
	OLTP -- for warehouse

	OLAP (online analytical processing) is a computing method that
	enables users to easily and selectively extract and query data in
	order to analyze it from different points of view.

	By data storage mode, OLAP is three types:
	1) MOLAP is a multi-dimensional storage mode
	2) ROLAP is a relational mode of storage
	3) HOLAP is a combination of multi-dimensional and relational elements.

star schema (or) dimension modelling
	-  fact tables are used to record a business event and dimension tables are used to record the attributes of business items(eg user, item tables in an e-commerce app).
	- For example, in an e-commerce website, a fact table would contain information about orders, such as when the order was placed, the items in that order, who placed that order, etc. The dimension tables would be an item table (containing item id, item price, size, etc) and an user table (containing user id, user name, user address etc).

slowly changing dimensions


- Fact Table
	- A fact table is a primary table in a dimensional model.
	- A Fact Table contains
		1) Measurements/facts
		2) Foreign key to dimension table


- Dimension Table
	- A dimension table contains dimensions of a fact.
	- They are joined to fact table via a foreign key.
	- Dimension tables are de-normalized tables.
	- The Dimension Attributes are the various columns in a dimension table
	- Dimensions offers descriptive characteristics of the facts with the help of their attributes
	- No set limit set for given for number of dimensions
	- The dimension can also contain one or more hierarchical relationships

- Fact table vs Dimension table
	- Fact table contains measurements, metrics, and facts about a business process, while the
	  Dimension table is a companion to the fact table, which contains descriptive attributes to be used as query constraining.
	- Fact table is located at the center of a star or snowflake schema, whereas the
	  Dimension table is located at the edges of the star or snowflake schema.
	- Fact table is defined by its grain or most atomic level, whereas a Dimension table
	  should be wordy, descriptive, complete, and of assured quality.
	- Fact table helps to store report labels, whereas Dimension table contains detailed data.
	- Fact table does not contain a hierarchy, whereas the Dimension table contains hierarchies.

- Fact Table Types
	1) Additive		->  Measures should be added to all dimensions.
	2) Semi-Additive->	In this type of facts, measures may be added to some dimensions and not with others.
	3) Non-Additive	->	It stores some basic unit of measurement of a business process.
	                    Some real-world examples include sales, phone calls, and orders.

- Dimension Table Types
	1) Conformed Dimensions
		- Conformed dimensions is the very fact to which it relates.
		- This dimension is used in more than one-star schema or Datamart.
	2) Outrigger Dimensions
		- A dimension may have a reference to another dimension table.
		- These secondary dimensions called outrigger dimensions.
		- This kind of Dimensions should be used carefully.
	3) Shrunken Rollup Dimensions
		- Shrunken Rollup dimensions are a subdivision of rows and columns of a base dimension.
		- These kinds of dimensions are useful for developing aggregated fact tables.
	4) Dimension-to-Dimension Table Joins
		- Dimensions may have references to other dimensions.
		- However, these relationships can be modeled with outrigger dimensions.
	5) Role-Playing Dimensions
		- A single physical dimension helps to reference multiple times in a fact table as each reference linking to a logically distinct role for the dimension.
	6) Junk Dimensions
		- It a collection of random transactional codes, flags or text attributes.
		- It may not logically belong to any specific dimension.
	7) Degenerate Dimensions
		- Degenerate dimension is without corresponding dimension. It is used in the transaction and collecting snapshot fact tables.
		- This kind of dimension does not have its dimension as it is derived from the fact table.
	8) Swappable Dimensions
		- They are used when the same fact table is paired with different versions of the same dimension.
	9) Step Dimensions
		- Sequential processes, like web page events, mostly have a separate row in a fact table for every step in a process. It tells where the specific step should be used in the overall session.

DataMart vs DataWarehouse Vs DataBase vs Operational DataStore
	- https://www.zuar.com/blog/data-mart-vs-data-warehouse-vs-database-vs-data-lake/

Data warehouse vs DataMart
	- data warehouses are built to serve as the central store of data for the entire business,
	- data mart fulfills the request of a specific division or business function.

	- In terms of range,
		- a data mart is limited to a single focus for one line of business;
		- a data warehouse is typically enterprise-wide and ranges across multiple areas.
	- And, in terms of sources,
		- a data mart includes data from just a few sources;
		- a data warehouse stores data from multiple sources.

Q) How to get last day of previous month?

	SELECT LAST_DAY(CURDATE());						-- Current month
	SELECT LAST_DAY(CURDATE() - INTERVAL 1 MONTH);	-- Previous month
	SELECT LAST_DAY(CURDATE() + INTERVAL 1 MONTH);	-- Next month


DB Design Books
===============
	SRE book, https://sre.google/sre-book/table-of-contents/
	Designing Data-Intensive Applications (O’Reilly)
	Streaming Systems (O’Reilly)
	Clean Code


CAP Theorem
===========
Consistency        : Every read receives the most recent write or an error
Availability       : Every request receives a (non-error) response, without the guarantee that it contains the most recent write
Partition tolerance: The system continues to operate despite an arbitrary number of messages being dropped (or delayed) by the network between nodes

- When a network partition failure happens should we decide to
	- Cancel the operation and thus decrease the availability but ensure consistency
	- Proceed with the operation and thus provide availability but risk inconsistency

- It is impossible for distributed systems to guarantee consistency, availability and partition tolerance at same time.
- Apache cassandra is an AP system; means availability and partition tolerance holds true,
	but not for Consistency but this can further tuned via replication factor(how many copies of data) and consistency level (read and write).

DB Partitioning
===============
- Partitioning is the db process where very large tables are divided into multiple smaller parts.
- It is done mainly for manageability, performance or availability reasons, or for load balancing
- This helps in maintenance of large tables and to reduce overall response time to read/load data for particular SQL operations.
- popular in distributed database management systems, where each partition may be spread over multiple nodes, with users at the node performing local transactions on the partition.
- They are of TWO types
	1) Vertical DB partitioning
	- Vertical partitioning splits a table into two or more tables containing different columns
	- To reduce access times, wide text or BLOB columns can be split to its own table.
	- Another example is to restrict access to sensitive data e.g. passwords, salary information etc.
	2) Horizontal partitioning involves putting different rows into different tables.
	- A view with a union of these partitions, will provide complete view of all customers.


TODO
	https://learnsql.com/

	• Intro to SQL 			➤ https://lnkd.in/eq6_-KqX
	• SQL Tutorial 			➤ https://lnkd.in/eSZAFVrJ
	• SQL for Data Analysis ➤ https://lnkd.in/e6RMcn7g
	• SQL Notes 			➤ https://lnkd.in/ejy_tqHz
